{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a8b70b",
   "metadata": {},
   "source": [
    "# Binary classification with *k*-nearest neighbours on Gaussian data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8d3bb",
   "metadata": {},
   "source": [
    "This notebook illustrates some of the basic principles of supervised machine learning using a k-nearest neighbours approach. The basic output is a video file displaying how the decision boundary classifying two 2D point clusters changes with *k*, and how the classification performance changes from underfitting large *k* values to overfitting with small *k*, passing nicely through an accuracy maximum (error minimum) somewhere in between. This bias-variance tradeoff to maximise real-world performance is fundamental to statistical model building. \n",
    "\n",
    "This notebook absolutely does not capture the challenges of real-world model building, including, but not limited, selection bias, non-parametric distributions (as opposed to nice, analytic Gaussians), data sparsity, having many (hyper)parameters rather than just one (*k*), etc.\n",
    "\n",
    "\n",
    "A video summarising the output of the noteboook is available here: https://www.youtube.com/watch?v=bmDdo_5IP2k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d75fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import model_selection, neighbors\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import random\n",
    "\n",
    "#plt.rcParams['pcolor.shading']\n",
    "pd.options.mode.chained_assignment = None\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c965adf",
   "metadata": {},
   "source": [
    "## 1. Generate data \n",
    "\n",
    "Firstly, generate data points from two bivariate Gaussian distributions. For example, height and weight for adult men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c6f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Gaussian distribution parameters and number of data points\n",
    "n_0 = 1000                         # number of data points in class 0\n",
    "n_1 = 1000                         # number of data points in class 1\n",
    "mean_0 = [0.5, 3]                  # mean of class 0 data\n",
    "cov_0 = [[1.5, 0.0], [0.0, 1.5]]   # covariance matrix of class 0 data\n",
    "mean_1 = [0, 0]                    # mean of class 1 data\n",
    "cov_1 = [[1.2, 0.0], [0.0, 1.2]]   # covariance matrix of class 1 data\n",
    "\n",
    "# Train / test split\n",
    "test_set_size = 0.5                # % of data held out for test set\n",
    "\n",
    "# Create data points and place into dataframes with class label column\n",
    "x1_0, x2_0 = np.random.multivariate_normal(mean_0, cov_0, n_0).T\n",
    "x1_1, x2_1 = np.random.multivariate_normal(mean_1, cov_1, n_1).T\n",
    "\n",
    "c0 = pd.DataFrame(np.transpose([x1_0, x2_0]), columns=['x1', 'x2'])\n",
    "c0['class'] = 0\n",
    "c1 = pd.DataFrame(np.transpose([x1_1, x2_1]), columns=['x1', 'x2'])\n",
    "c1['class'] = 1\n",
    "\n",
    "# Concatenate into single dataframe\n",
    "df = pd.concat([c1, c0]).reset_index()\n",
    "\n",
    "# Assign training / test labels\n",
    "df['dataset'] = random.choices(['train', 'test'],\n",
    "                               weights = [1-test_set_size, test_set_size],\n",
    "                               k = n_0+n_1)\n",
    "\n",
    "# Resolve data into training/test sets\n",
    "X_trn = df[(df['dataset'] == 'train')][['x1', 'x2']]\n",
    "X_tst = df[(df['dataset'] == 'test')][['x1', 'x2']]\n",
    "y_trn = df[(df['dataset'] == 'train')]['class']\n",
    "y_tst = df[(df['dataset'] == 'test')]['class']\n",
    "\n",
    "# Resolve data into training/test sets, further resolved into the different target values\n",
    "X_trn_1 = df[(df['dataset'] == 'train') & (df['class'] == 1)][['x1', 'x2']].values\n",
    "X_trn_0 = df[(df['dataset'] == 'train') & (df['class'] == 0)][['x1', 'x2']].values\n",
    "X_tst_1 = df[(df['dataset'] == 'test')  & (df['class'] == 1)][['x1', 'x2']].values\n",
    "X_tst_0 = df[(df['dataset'] == 'test')  & (df['class'] == 0)][['x1', 'x2']].values\n",
    "y_trn_1 = df[(df['dataset'] == 'train') & (df['class'] == 1)]['class'].values\n",
    "y_trn_0 = df[(df['dataset'] == 'train') & (df['class'] == 0)]['class'].values\n",
    "y_tst_1 = df[(df['dataset'] == 'test')  & (df['class'] == 1)]['class'].values\n",
    "y_tst_0 = df[(df['dataset'] == 'test')  & (df['class'] == 0)]['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9dc9da",
   "metadata": {},
   "source": [
    "## 2. Prepare background grid in the feature space for plotting the prediction regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1b2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background grid fineness. Reduce to about 100 for a *significant* speedup\n",
    "grid_resolution = 300\n",
    "\n",
    "# Form a regular 2D grid spanning the entire feature space\n",
    "x1_grid = np.linspace(min(df['x1']), max(df['x1']), grid_resolution)\n",
    "x2_grid = np.linspace(min(df['x2']), max(df['x2']), grid_resolution)\n",
    "ee, nn = np.meshgrid(x1_grid, x2_grid)\n",
    "\n",
    "# Flatten meshgrid to create two-column array of all coordinate pairs\n",
    "prediction_grid = np.vstack([np.ravel(nn), np.ravel(ee)]).T\n",
    "prediction_grid = np.flip(prediction_grid, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5490a493",
   "metadata": {},
   "source": [
    "## 3. Perform successive predictions over range of *k* values and output images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b6e36b",
   "metadata": {},
   "source": [
    "First create some functions to i) obtain the confusion matrix for a given value of *k*, and ii) to create and save a figure displaying everything that's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71abbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix_elements(x_set_1, x_set_0, y_set_1, y_set_0, classifier):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the elements of the confusion matrix from a binary classifier applied to \n",
    "    an array of input data (x) and output classes (y)\n",
    "    \"\"\"\n",
    "    \n",
    "    y_set_1_pred = classifier.predict(x_set_1)\n",
    "    y_set_0_pred = classifier.predict(x_set_0)\n",
    "\n",
    "    tp_set = y_set_1_pred == y_set_1\n",
    "    fn_set = y_set_1_pred != y_set_1\n",
    "    tn_set = y_set_0_pred == y_set_0\n",
    "    fp_set = y_set_0_pred != y_set_0\n",
    "\n",
    "    x_set_tp = x_set_1[tp_set]\n",
    "    x_set_fn = x_set_1[fn_set]\n",
    "    x_set_tn = x_set_0[tn_set]\n",
    "    x_set_fp = x_set_0[fp_set]\n",
    "\n",
    "    return x_set_tp, x_set_fn, x_set_tn, x_set_fp\n",
    "\n",
    "def save_image(df_,\n",
    "               k_max_,\n",
    "               ee_,\n",
    "               nn_,\n",
    "               decision_regions_,\n",
    "               X_trn_tp_, \n",
    "               X_trn_fn_, \n",
    "               X_trn_tn_, \n",
    "               X_trn_fp_, \n",
    "               X_tst_tp_, \n",
    "               X_tst_fn_, \n",
    "               X_tst_tn_, \n",
    "               X_tst_fp_, \n",
    "               one_over_k_,\n",
    "               test_error_rate_,\n",
    "               train_error_rate_,\n",
    "               sensitivity_tst_,\n",
    "               specificity_tst_,\n",
    "               sensitivity_trn_,\n",
    "               specificity_trn_,\n",
    "               k_, \n",
    "              ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plots a four-panel image summarising the training data, test data, classificaion\n",
    "    regions, and classification metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise plotting figure\n",
    "    fig = plt.figure(figsize=(1920/100,  1080/100))\n",
    "    custom_colors = ListedColormap(['#A1E1FF', '#FFC8C6'])\n",
    "\n",
    "    ax1 = plt.subplot2grid((2, 5), (0,0), colspan=2, rowspan=2)\n",
    "    ax2 = plt.subplot2grid((2, 5), (0,3), colspan=2, rowspan=2)\n",
    "    ax3 = plt.subplot2grid((2, 5), (0,2), colspan=1, rowspan=1)\n",
    "    ax4 = plt.subplot2grid((2, 5), (1,2), colspan=1, rowspan=1)\n",
    "\n",
    "    ax1.set_xlabel(r'$x_1$')\n",
    "    ax1.set_ylabel(r'$x_2$')\n",
    "    ax1.set_xlim([min(df_['x1']), max(df_['x1'])])\n",
    "    ax1.set_ylim([min(df_['x2']), max(df_['x2'])])\n",
    "\n",
    "    ax2.set_xlabel(r'$x_1$')\n",
    "    ax2.set_ylabel(r'$x_2$')\n",
    "    ax2.set_xlim([min(df_['x1']), max(df_['x1'])])\n",
    "    ax2.set_ylim([min(df_['x2']), max(df_['x2'])])\n",
    "\n",
    "    ax3.set_xlabel(r'1/k')\n",
    "    ax3.set_ylabel('error')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.set_xlim([1/k_max_, 1])\n",
    "    ax3.xaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    ax3.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax3.set_title('Error rates vs. 1/k')\n",
    "\n",
    "    ax4.set_xlabel(r'1/k')\n",
    "    ax4.set_ylabel('sensitivity / specificity')\n",
    "    ax4.set_xscale('log')\n",
    "    ax4.set_xlim([1/k_max_, 1])\n",
    "    ax4.xaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    ax4.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax4.set_title('Sens./Spec. vs. 1/k')\n",
    "\n",
    "    # plot prediction regions\n",
    "    ax1.pcolor(ee_, nn_,  decision_regions_, cmap=custom_colors, shading='auto')\n",
    "    ax2.pcolor(ee_, nn_,  decision_regions_, cmap=custom_colors, shading='auto')\n",
    "\n",
    "    # plot the training data scatter plot\n",
    "    ax1.scatter(X_trn_tp_[:, 0], X_trn_tp_[:, 1], s=50, marker='.', c='red', label='true positives ({0} set)'.format('training'))\n",
    "    ax1.scatter(X_trn_fn_[:, 0], X_trn_fn_[:, 1], s=50, marker='x', c='red', label='false negatives ({0} set)'.format('training'))\n",
    "    ax1.scatter(X_trn_tn_[:, 0], X_trn_tn_[:, 1], s=50, marker='.', c='blue', label='true negatives ({0} set)'.format('training'))\n",
    "    ax1.scatter(X_trn_fp_[:, 0], X_trn_fp_[:, 1], s=50, marker='x', c='blue', label='false positives ({0} set)'.format('training'))\n",
    "    ax1.set_title('{0}-nearest neighbours binary classifier: training set'.format(k), fontsize=14)\n",
    "\n",
    "    # plot the test data scatter plot\n",
    "    ax2.scatter(X_tst_tp_[:, 0], X_tst_tp_[:, 1], s=50, marker='.', c='red', label='true positives ({0} set)'.format('test'))\n",
    "    ax2.scatter(X_tst_fn_[:, 0], X_tst_fn_[:, 1], s=50, marker='x', c='red', label='false negatives ({0} set)'.format('test'))\n",
    "    ax2.scatter(X_tst_tn_[:, 0], X_tst_tn_[:, 1], s=50, marker='.', c='blue', label='true negatives ({0} set)'.format('test'))\n",
    "    ax2.scatter(X_tst_fp_[:, 0], X_tst_fp_[:, 1], s=50, marker='x', c='blue', label='false positives ({0} set)'.format('test'))\n",
    "    ax2.set_title('{0}-nearest neighbours binary classifier: test set'.format(k), fontsize=14)\n",
    "\n",
    "    # plot test error array against 1/k array\n",
    "    ax3.plot(one_over_k_, test_error_rate_, color='black', lw='2', label='test error')\n",
    "    ax3.plot(one_over_k_, train_error_rate_, color='red', lw='2', label='training error')\n",
    "\n",
    "    # plot sensitivity and specificity arrays against 1/k array\n",
    "    ax4.plot(one_over_k_, sensitivity_tst_, c='black', lw='2', label='sensitivity (test set)')\n",
    "    ax4.plot(one_over_k_, specificity_tst_, c='green', lw='2', label='specificity (test set)')\n",
    "    ax4.plot(one_over_k_, sensitivity_trn_, c='red', lw='2', label='sensitivity (training set)')\n",
    "    ax4.plot(one_over_k_, specificity_trn_, c='fuchsia', lw='2', label='specificity (training set)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax3.legend(loc='lower left')\n",
    "    ax4.legend(loc='lower right')\n",
    "\n",
    "    plt.savefig('images/{0}_knn.png'.format(k_))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c28b6",
   "metadata": {},
   "source": [
    "Next, create a directory for the images to be saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ca906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b5f48",
   "metadata": {},
   "source": [
    "Loop through some values of *k*, and generate the image displaying the model prediction regions and decision boundary overlaid onto the training and test sets, along with two graphs showing the error (1 - accuracy), specificity (how often the model gets it right for the blue points), and sensitivity (how often it gets it right for the red points). Save these images to the directory just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "104bd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty arrays to be populated in the loop for error vs. 1/k plot\n",
    "one_over_k = np.empty(0)\n",
    "test_error_rate = np.empty(0)\n",
    "train_error_rate = np.empty(0)\n",
    "sensitivity_tst = np.empty(0)\n",
    "specificity_tst = np.empty(0)\n",
    "sensitivity_trn = np.empty(0)\n",
    "specificity_trn = np.empty(0)\n",
    "\n",
    "# Loop variables\n",
    "k_max = 501                        # max number of neighbours considered\n",
    "k_min = 1                          # min number of neighbours considered\n",
    "step = 2                           # step between k values\n",
    "\n",
    "# loop to produce successive images over k range\n",
    "for k in range(k_max, k_min-1, -step):\n",
    "\n",
    "    # Fit the training data\n",
    "    clf = neighbors.KNeighborsClassifier(k)\n",
    "    clf.fit(X_trn, y_trn)\n",
    "\n",
    "    # Pass the coordinate pairs to the classifier to return class predictions for each point\n",
    "    decision_regions = clf.predict(prediction_grid)\n",
    "\n",
    "    # Repackage the class predictions into the shape corresponding to the meshgrid\n",
    "    decision_regions = decision_regions.reshape(ee.shape)\n",
    "\n",
    "    # classify training and test sets corresponding to entries of confusion matrix\n",
    "    X_trn_tp, X_trn_fn, X_trn_tn, X_trn_fp = \\\n",
    "    get_confusion_matrix_elements(X_trn_1, X_trn_0, y_trn_1, y_trn_0, clf)\n",
    "    \n",
    "    X_tst_tp, X_tst_fn, X_tst_tn, X_tst_fp = \\\n",
    "    get_confusion_matrix_elements(X_tst_1, X_tst_0, y_tst_1, y_tst_0, clf)\n",
    "\n",
    "    # count number of true positives, false positives, true negatives and false negatives\n",
    "    tst_tp, tst_fn, tst_tn, tst_fp = len(X_tst_tp), len(X_tst_fn), len(X_tst_tn), len(X_tst_fp)\n",
    "    trn_tp, trn_fn, trn_tn, trn_fp = len(X_trn_tp), len(X_trn_fn), len(X_trn_tn), len(X_trn_fp)\n",
    "\n",
    "    # form arrays of error rates (updates with each kth loop iteration)\n",
    "    test_error_rate = \\\n",
    "    np.append(test_error_rate, np.array([(tst_fn + tst_fp) / (tst_tp + tst_fn + tst_tn + tst_fp)]))\n",
    "    \n",
    "    train_error_rate = \\\n",
    "    np.append(train_error_rate, np.array([(trn_fn + trn_fp) / (trn_tp + trn_fn + trn_tn + trn_fp)]))\n",
    "\n",
    "    # array of 1/k values for plotting test and training error\n",
    "    one_over_k = np.append(one_over_k, np.array([1/k]))\n",
    "\n",
    "    sensitivity_tst = np.append(sensitivity_tst, np.array([tst_tp / (tst_tp + tst_fn)]))\n",
    "    specificity_tst = np.append(specificity_tst, np.array([tst_tn / (tst_tn + tst_fp)]))\n",
    "    sensitivity_trn = np.append(sensitivity_trn, np.array([trn_tp / (trn_tp + trn_fn)]))\n",
    "    specificity_trn = np.append(specificity_trn, np.array([trn_tn / (trn_tn + trn_fp)]))\n",
    "\n",
    "    save_image(df_=df,\n",
    "               k_max_=k_max,\n",
    "               ee_=ee,\n",
    "               nn_=nn,\n",
    "               decision_regions_=decision_regions,   \n",
    "               X_trn_tp_=X_trn_tp, \n",
    "               X_trn_fn_=X_trn_fn, \n",
    "               X_trn_tn_=X_trn_tn, \n",
    "               X_trn_fp_=X_trn_fp, \n",
    "               X_tst_tp_=X_tst_tp, \n",
    "               X_tst_fn_=X_tst_fn, \n",
    "               X_tst_tn_=X_tst_tn, \n",
    "               X_tst_fp_=X_tst_fp, \n",
    "               one_over_k_=one_over_k,\n",
    "               test_error_rate_=test_error_rate,\n",
    "               train_error_rate_=train_error_rate,\n",
    "               sensitivity_tst_=sensitivity_tst,\n",
    "               specificity_tst_=specificity_tst,\n",
    "               sensitivity_trn_=sensitivity_trn,\n",
    "               specificity_trn_=specificity_trn,\n",
    "               k_=k,\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758ddb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3.1 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/opt/conda --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1609680890771/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1609680890771/_build_env/bin/pkg-config\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "Input #0, image2, from 'images/*.png':\n",
      "  Duration: 00:00:03.57, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgba(pc), 1382x777 [SAR 2835:2835 DAR 1382:777], 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mprofile High 4:4:4 Predictive, level 3.2, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0m264 - core 161 r3030M 8bd6d28 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'video.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv444p, 1382x777 [SAR 1:1 DAR 1382:777], q=-1--1, 30 fps, 15360 tbn, 30 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.91.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  107 fps= 30 q=-1.0 Lsize=     201kB time=00:00:03.46 bitrate= 474.2kbits/s speed=0.988x    \n",
      "video:199kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.053967%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mframe I:1     Avg QP:18.90  size:118950\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mframe P:27    Avg QP:25.65  size:  1651\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mframe B:79    Avg QP:28.87  size:   495\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mconsecutive B-frames:  0.9%  1.9%  0.0% 97.2%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mmb I  I16..4: 27.8% 35.0% 37.3%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mmb P  I16..4:  0.4%  0.2%  0.1%  P16..4:  1.9%  0.6%  0.3%  0.0%  0.0%    skip:96.5%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mmb B  I16..4:  0.0%  0.2%  0.0%  B16..8:  1.8%  0.1%  0.0%  direct: 0.4%  skip:97.4%  L0:54.9% L1:44.3% BI: 0.8%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0m8x8 transform intra:40.2% inter:8.4%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mcoded y,u,v intra: 18.2% 12.6% 12.1% inter: 0.1% 0.2% 0.3%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mi16 v,h,dc,p: 60% 35%  6%  0%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 39%  8% 52%  0%  0%  0%  0%  0%  0%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45% 19% 15%  3%  4%  4%  4%  3%  3%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mref P L0: 50.4%  7.1% 25.6% 17.0%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mref B L0: 72.0% 25.5%  2.5%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mref B L1: 93.4%  6.6%\n",
      "\u001b[1;36m[libx264 @ 0x5595ac51d000] \u001b[0mkb/s:454.52\n"
     ]
    }
   ],
   "source": [
    "# create video from images\n",
    "!ffmpeg -y -framerate 30 -pattern_type glob -i 'images/*.png' video.mp4"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
