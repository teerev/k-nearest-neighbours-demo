{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae83c50a",
   "metadata": {},
   "source": [
    "# Binary classification with *k*-nearest neighbours on Gaussian data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313b720",
   "metadata": {},
   "source": [
    "This notebook illustrates some of the basic principles of machine learning using a k-nearest neighbours approach.\n",
    "\n",
    "A video summarising the output of the noteboook is available here: https://www.youtube.com/watch?v=bmDdo_5IP2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f3c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import model_selection, neighbors\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import random\n",
    "\n",
    "#plt.rcParams['pcolor.shading']\n",
    "pd.options.mode.chained_assignment = None\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf277b15",
   "metadata": {},
   "source": [
    "## 1. Generate data \n",
    "\n",
    "Firstly, generate data points from two bivariate Gaussian distributions. For example, height and weight for adult men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40deab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Gaussian distribution parameters and number of data points\n",
    "n_0 = 1000                         # number of data points in class 0\n",
    "n_1 = 1000                         # number of data points in class 1\n",
    "mean_0 = [0.5, 3]                  # mean of class 0 data\n",
    "cov_0 = [[1.5, 0.0], [0.0, 1.5]]   # covariance matrix of class 0 data\n",
    "mean_1 = [0, 0]                    # mean of class 1 data\n",
    "cov_1 = [[1.2, 0.0], [0.0, 1.2]]   # covariance matrix of class 1 data\n",
    "\n",
    "# Train / test split\n",
    "test_set_size = 0.5                # % of data held out for test set\n",
    "\n",
    "# Create data points and place into dataframes with class label column\n",
    "x1_0, x2_0 = np.random.multivariate_normal(mean_0, cov_0, n_0).T\n",
    "x1_1, x2_1 = np.random.multivariate_normal(mean_1, cov_1, n_1).T\n",
    "\n",
    "c0 = pd.DataFrame(np.transpose([x1_0, x2_0]), columns=['x1', 'x2'])\n",
    "c0['class'] = 0\n",
    "c1 = pd.DataFrame(np.transpose([x1_1, x2_1]), columns=['x1', 'x2'])\n",
    "c1['class'] = 1\n",
    "\n",
    "# Concatenate into single dataframe\n",
    "df = pd.concat([c1, c0]).reset_index()\n",
    "\n",
    "# Assign training / test labels\n",
    "df['dataset'] = random.choices(['train', 'test'],\n",
    "                               weights = [1-test_set_size, test_set_size],\n",
    "                               k = n_0+n_1)\n",
    "\n",
    "# Resolve data into training/test sets\n",
    "X_trn = df[(df['dataset'] == 'train')][['x1', 'x2']]\n",
    "X_tst = df[(df['dataset'] == 'test')][['x1', 'x2']]\n",
    "y_trn = df[(df['dataset'] == 'train')]['class']\n",
    "y_tst = df[(df['dataset'] == 'test')]['class']\n",
    "\n",
    "# Resolve data into training/test sets, further resolved into the different target values\n",
    "X_trn_1 = df[(df['dataset'] == 'train') & (df['class'] == 1)][['x1', 'x2']].values\n",
    "X_trn_0 = df[(df['dataset'] == 'train') & (df['class'] == 0)][['x1', 'x2']].values\n",
    "X_tst_1 = df[(df['dataset'] == 'test')  & (df['class'] == 1)][['x1', 'x2']].values\n",
    "X_tst_0 = df[(df['dataset'] == 'test')  & (df['class'] == 0)][['x1', 'x2']].values\n",
    "y_trn_1 = df[(df['dataset'] == 'train') & (df['class'] == 1)]['class'].values\n",
    "y_trn_0 = df[(df['dataset'] == 'train') & (df['class'] == 0)]['class'].values\n",
    "y_tst_1 = df[(df['dataset'] == 'test')  & (df['class'] == 1)]['class'].values\n",
    "y_tst_0 = df[(df['dataset'] == 'test')  & (df['class'] == 0)]['class'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d817b6d",
   "metadata": {},
   "source": [
    "## 2. Prepare background grid in the feature space for plotting the prediction regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c43fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background grid fineness\n",
    "grid_resolution = 100\n",
    "\n",
    "# Form a regular 2D grid spanning the entire feature space\n",
    "x1_grid = np.linspace(min(df['x1']), max(df['x1']), grid_resolution)\n",
    "x2_grid = np.linspace(min(df['x2']), max(df['x2']), grid_resolution)\n",
    "ee, nn = np.meshgrid(x1_grid, x2_grid)\n",
    "\n",
    "# Flatten meshgrid to create two-column array of all coordinate pairs\n",
    "prediction_grid = np.vstack([np.ravel(nn), np.ravel(ee)]).T\n",
    "prediction_grid = np.flip(prediction_grid, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e65c2",
   "metadata": {},
   "source": [
    "## 3. Perform successive predictions over range of *k* values and output images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae85b8a",
   "metadata": {},
   "source": [
    "First create some functions to i) obtain the confusion matrix for a given value of *k*, and ii) to create and save a figure displaying everything that's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a601491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix_elements(x_set_1, x_set_0, y_set_1, y_set_0, classifier):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the elements of the confusion matrix from a binary classifier applied to \n",
    "    an array of input data (x) and output classes (y)\n",
    "    \"\"\"\n",
    "    \n",
    "    y_set_1_pred = classifier.predict(x_set_1)\n",
    "    y_set_0_pred = classifier.predict(x_set_0)\n",
    "\n",
    "    tp_set = y_set_1_pred == y_set_1\n",
    "    fn_set = y_set_1_pred != y_set_1\n",
    "    tn_set = y_set_0_pred == y_set_0\n",
    "    fp_set = y_set_0_pred != y_set_0\n",
    "\n",
    "    x_set_tp = x_set_1[tp_set]\n",
    "    x_set_fn = x_set_1[fn_set]\n",
    "    x_set_tn = x_set_0[tn_set]\n",
    "    x_set_fp = x_set_0[fp_set]\n",
    "\n",
    "    return x_set_tp, x_set_fn, x_set_tn, x_set_fp\n",
    "\n",
    "def save_image(df_,\n",
    "               k_max_,\n",
    "               ee_,\n",
    "               nn_,\n",
    "               decision_regions_,\n",
    "               X_trn_tp_, \n",
    "               X_trn_fn_, \n",
    "               X_trn_tn_, \n",
    "               X_trn_fp_, \n",
    "               X_tst_tp_, \n",
    "               X_tst_fn_, \n",
    "               X_tst_tn_, \n",
    "               X_tst_fp_, \n",
    "               one_over_k_,\n",
    "               test_error_rate_,\n",
    "               train_error_rate_,\n",
    "               sensitivity_tst_,\n",
    "               specificity_tst_,\n",
    "               sensitivity_trn_,\n",
    "               specificity_trn_,\n",
    "               k_, \n",
    "              ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plots a four-panel image summarising the training data, test data, classificaion\n",
    "    regions, and classification metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise plotting figure\n",
    "    fig = plt.figure(figsize=(1920/100,  1080/100))\n",
    "    custom_colors = ListedColormap(['#A1E1FF', '#FFC8C6'])\n",
    "\n",
    "    ax1 = plt.subplot2grid((2, 5), (0,0), colspan=2, rowspan=2)\n",
    "    ax2 = plt.subplot2grid((2, 5), (0,3), colspan=2, rowspan=2)\n",
    "    ax3 = plt.subplot2grid((2, 5), (0,2), colspan=1, rowspan=1)\n",
    "    ax4 = plt.subplot2grid((2, 5), (1,2), colspan=1, rowspan=1)\n",
    "\n",
    "    ax1.set_xlabel(r'$x_1$')\n",
    "    ax1.set_ylabel(r'$x_2$')\n",
    "    ax1.set_xlim([min(df_['x1']), max(df_['x1'])])\n",
    "    ax1.set_ylim([min(df_['x2']), max(df_['x2'])])\n",
    "\n",
    "    ax2.set_xlabel(r'$x_1$')\n",
    "    ax2.set_ylabel(r'$x_2$')\n",
    "    ax2.set_xlim([min(df_['x1']), max(df_['x1'])])\n",
    "    ax2.set_ylim([min(df_['x2']), max(df_['x2'])])\n",
    "\n",
    "    ax3.set_xlabel(r'1/k')\n",
    "    ax3.set_ylabel('error')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.set_xlim([1/k_max_, 1])\n",
    "    ax3.xaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    ax3.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax3.set_title('Error rates vs. 1/k')\n",
    "\n",
    "    ax4.set_xlabel(r'1/k')\n",
    "    ax4.set_ylabel('sensitivity / specificity')\n",
    "    ax4.set_xscale('log')\n",
    "    ax4.set_xlim([1/k_max_, 1])\n",
    "    ax4.xaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    ax4.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax4.set_title('Sens./Spec. vs. 1/k')\n",
    "\n",
    "    # plot prediction regions\n",
    "    ax1.pcolor(ee_, nn_,  decision_regions_, cmap=custom_colors, shading='auto')\n",
    "    ax2.pcolor(ee_, nn_,  decision_regions_, cmap=custom_colors, shading='auto')\n",
    "\n",
    "    # plot the training data scatter plot\n",
    "    ax1.scatter(X_trn_tp_[:, 0], X_trn_tp_[:, 1], s=50, marker='.', c='red', label='true positives ({0} set)'.format('training'))\n",
    "    ax1.scatter(X_trn_fn_[:, 0], X_trn_fn_[:, 1], s=50, marker='x', c='red', label='false negatives ({0} set)'.format('training'))\n",
    "    ax1.scatter(X_trn_tn_[:, 0], X_trn_tn_[:, 1], s=50, marker='.', c='blue', label='true negatives ({0} set)'.format('training'))\n",
    "    ax1.scatter(X_trn_fp_[:, 0], X_trn_fp_[:, 1], s=50, marker='x', c='blue', label='false positives ({0} set)'.format('training'))\n",
    "    ax1.set_title('{0}-nearest neighbours binary classifier: training set'.format(k), fontsize=14)\n",
    "\n",
    "    # plot the test data scatter plot\n",
    "    ax2.scatter(X_tst_tp_[:, 0], X_tst_tp_[:, 1], s=50, marker='.', c='red', label='true positives ({0} set)'.format('test'))\n",
    "    ax2.scatter(X_tst_fn_[:, 0], X_tst_fn_[:, 1], s=50, marker='x', c='red', label='false negatives ({0} set)'.format('test'))\n",
    "    ax2.scatter(X_tst_tn_[:, 0], X_tst_tn_[:, 1], s=50, marker='.', c='blue', label='true negatives ({0} set)'.format('test'))\n",
    "    ax2.scatter(X_tst_fp_[:, 0], X_tst_fp_[:, 1], s=50, marker='x', c='blue', label='false positives ({0} set)'.format('test'))\n",
    "    ax2.set_title('{0}-nearest neighbours binary classifier: test set'.format(k), fontsize=14)\n",
    "\n",
    "    # plot test error array against 1/k array\n",
    "    ax3.plot(one_over_k_, test_error_rate_, color='black', lw='2', label='test error')\n",
    "    ax3.plot(one_over_k_, train_error_rate_, color='red', lw='2', label='training error')\n",
    "\n",
    "    # plot sensitivity and specificity arrays against 1/k array\n",
    "    ax4.plot(one_over_k_, sensitivity_tst_, c='black', lw='2', label='sensitivity (test set)')\n",
    "    ax4.plot(one_over_k_, specificity_tst_, c='green', lw='2', label='specificity (test set)')\n",
    "    ax4.plot(one_over_k_, sensitivity_trn_, c='red', lw='2', label='sensitivity (training set)')\n",
    "    ax4.plot(one_over_k_, specificity_trn_, c='fuchsia', lw='2', label='specificity (training set)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax3.legend(loc='lower left')\n",
    "    ax4.legend(loc='lower right')\n",
    "\n",
    "    plt.savefig('images/{0}_knn.png'.format(k_))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbd42d",
   "metadata": {},
   "source": [
    "Next, create a directory for the images to be saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a20bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62d74f",
   "metadata": {},
   "source": [
    "Loop through some values of *k*, and generate the image displaying the model prediction regions overlaid onto the training and test sets, along with two graphs showing the error (1 - accuracy), specificity (how often the model gets it right for the blue points), and sensitivity (how often it gets it right for the reds points). Save these images to the directory just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9c1debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty arrays to be populated in the loop for error vs. 1/k plot\n",
    "one_over_k = np.empty(0)\n",
    "test_error_rate = np.empty(0)\n",
    "train_error_rate = np.empty(0)\n",
    "sensitivity_tst = np.empty(0)\n",
    "specificity_tst = np.empty(0)\n",
    "sensitivity_trn = np.empty(0)\n",
    "specificity_trn = np.empty(0)\n",
    "\n",
    "# Loop variables\n",
    "k_max = 501                        # max number of neighbours considered\n",
    "k_min = 1                          # min number of neighbours considered\n",
    "step = 2                           # step between k values\n",
    "\n",
    "# loop to produce successive images over k range\n",
    "for k in range(k_max, k_min-1, -step):\n",
    "\n",
    "    # Fit the training data\n",
    "    clf = neighbors.KNeighborsClassifier(k)\n",
    "    clf.fit(X_trn, y_trn)\n",
    "\n",
    "    # Pass the coordinate pairs to the classifier to return class predictions for each point\n",
    "    decision_regions = clf.predict(prediction_grid)\n",
    "\n",
    "    # Repackage the class predictions into the shape corresponding to the meshgrid\n",
    "    decision_regions = decision_regions.reshape(ee.shape)\n",
    "\n",
    "    # classify training and test sets corresponding to entries of confusion matrix\n",
    "    X_trn_tp, X_trn_fn, X_trn_tn, X_trn_fp = \\\n",
    "    get_confusion_matrix_elements(X_trn_1, X_trn_0, y_trn_1, y_trn_0, clf)\n",
    "    \n",
    "    X_tst_tp, X_tst_fn, X_tst_tn, X_tst_fp = \\\n",
    "    get_confusion_matrix_elements(X_tst_1, X_tst_0, y_tst_1, y_tst_0, clf)\n",
    "\n",
    "    # count number of true positives, false positives, true negatives and false negatives\n",
    "    tst_tp, tst_fn, tst_tn, tst_fp = len(X_tst_tp), len(X_tst_fn), len(X_tst_tn), len(X_tst_fp)\n",
    "    trn_tp, trn_fn, trn_tn, trn_fp = len(X_trn_tp), len(X_trn_fn), len(X_trn_tn), len(X_trn_fp)\n",
    "\n",
    "    # form arrays of error rates (updates with each kth loop iteration)\n",
    "    test_error_rate = \\\n",
    "    np.append(test_error_rate, np.array([(tst_fn + tst_fp) / (tst_tp + tst_fn + tst_tn + tst_fp)]))\n",
    "    \n",
    "    train_error_rate = \\\n",
    "    np.append(train_error_rate, np.array([(trn_fn + trn_fp) / (trn_tp + trn_fn + trn_tn + trn_fp)]))\n",
    "\n",
    "    # array of 1/k values for plotting test and training error\n",
    "    one_over_k = np.append(one_over_k, np.array([1/k]))\n",
    "\n",
    "    sensitivity_tst = np.append(sensitivity_tst, np.array([tst_tp / (tst_tp + tst_fn)]))\n",
    "    specificity_tst = np.append(specificity_tst, np.array([tst_tn / (tst_tn + tst_fp)]))\n",
    "    sensitivity_trn = np.append(sensitivity_trn, np.array([trn_tp / (trn_tp + trn_fn)]))\n",
    "    specificity_trn = np.append(specificity_trn, np.array([trn_tn / (trn_tn + trn_fp)]))\n",
    "\n",
    "    save_image(df_=df,\n",
    "               k_max_=k_max,\n",
    "               ee_=ee,\n",
    "               nn_=nn,\n",
    "               decision_regions_=decision_regions,   \n",
    "               X_trn_tp_=X_trn_tp, \n",
    "               X_trn_fn_=X_trn_fn, \n",
    "               X_trn_tn_=X_trn_tn, \n",
    "               X_trn_fp_=X_trn_fp, \n",
    "               X_tst_tp_=X_tst_tp, \n",
    "               X_tst_fn_=X_tst_fn, \n",
    "               X_tst_tn_=X_tst_tn, \n",
    "               X_tst_fp_=X_tst_fp, \n",
    "               one_over_k_=one_over_k,\n",
    "               test_error_rate_=test_error_rate,\n",
    "               train_error_rate_=train_error_rate,\n",
    "               sensitivity_tst_=sensitivity_tst,\n",
    "               specificity_tst_=specificity_tst,\n",
    "               sensitivity_trn_=sensitivity_trn,\n",
    "               specificity_trn_=specificity_trn,\n",
    "               k_=k,\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
